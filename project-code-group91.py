# -*- coding: utf-8 -*-
"""
Created on Fri May 15 14:45:30 2020

@author: meta
"""

import numpy as np
import os
from keras.datasets import cifar10
from keras.models import Sequential
from keras.layers import Dense, Conv2D
from keras.layers import Dropout
from keras.layers import Flatten
from keras.layers import BatchNormalization
from keras.optimizers import SGD, Adam
from keras.layers.convolutional import Convolution2D
from keras.layers.convolutional import MaxPooling2D
from keras.regularizers import l2
from keras.utils import np_utils
import matplotlib.pyplot as plt
from keras.preprocessing.image import ImageDataGenerator



def varalex(input_shape, num_classes = 10):
        
      model = Sequential()
      model.add(Conv2D(filters=96,kernel_size=(3,3),strides=(4,4),input_shape=input_shape, activation='relu'))
      model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))
      model.add(BatchNormalization())
      model.add(Conv2D(256,(5,5),padding='same',activation='relu'))
      model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))
      model.add(BatchNormalization())
      model.add(Conv2D(384,(3,3),padding='same',activation='relu'))
      model.add(Conv2D(384,(3,3),padding='same',activation='relu'))
      model.add(Conv2D(256,(3,3),padding='same',activation='relu'))
      model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))
      model.add(BatchNormalization())
    
      model.add(Flatten())
      #model.add(Dropout(0.4))
      model.add(Dense(4096, activation='relu'))
      #model.add(BatchNormalization())
      model.add(Dropout(0.4))
      model.add(Dense(4096, activation='relu'))
      model.add(Dropout(0.4))
      #model.add(BatchNormalization())
      model.add(Dense(num_classes,activation='softmax'))
      
      return model


###############################################################################
      #variables and settings
###############################################################################
      
      
DATASET = 'cifar-10'
input_shape=(32,32,3)
num_classes = 10

model_type = 'varalex'

#model settings:
epochs = 10
lrate = 0.00075
batch_size = 100
lr_v = np.linspace(0.0005,0.0015,5)
print(lr_v)

data_augmentation = True

###############################################################################
      #Load data and print some images
###############################################################################
      
      
(X_train, y_train),(X_test,y_test) = cifar10.load_data()
X_train=X_train[:500]
y_train=y_train[:500]
X_test=X_test[:100]
y_test=y_test[:100]
X_train.shape, X_test.shape, X_train.shape[1:],X_train.dtype



#Plot images
for i in range(0,9):
    plt.subplot(330+1+i)
    plt.imshow(X_train[i])
plt.show() 

    
###############################################################################
      #preprocessing
###############################################################################
      
      
if not data_augmentation:
        X_train = X_train.astype('float32')
        X_test = X_test.astype('float32')
     
y_train = np_utils.to_categorical(y_train)
y_test = np_utils.to_categorical(y_test)



###############################################################################
      #Compile model
###############################################################################
      
     
model = varalex(input_shape,num_classes)
#optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)
optimizer = SGD(lr=lrate, decay=0, nesterov=True)

model.compile(loss= 'categorical_crossentropy' , optimizer=optimizer, metrics=[ 'accuracy' ])

if data_augmentation:
    print('Using real-time data augmentation.')
    # This will do preprocessing and realtime data augmentation:
    datagen = ImageDataGenerator(

            rotation_range=20,
            horizontal_flip=True,
            width_shift_range=0.1,
            height_shift_range=0.1)

if not data_augmentation:
        print('Not using data augmentation.')
        history = model.fit(X_train, y_train,
          batch_size=batch_size,
          epochs=epochs,
          validation_data=(X_test, y_test),
          shuffle=True)
else:   
        print("model using data from downloaded dataset in memoory")
        datagen.fit(X_train)
        # Fit the model on the batches generated by datagen.flow().
        history = model.fit_generator(datagen.flow(X_train, y_train,
                                 batch_size=batch_size),
                                 epochs=epochs,
                                 validation_data=datagen.flow((X_test, y_test),batch_size=batch_size))

###############################################################################
      #Plotting
###############################################################################
      
#history
print(history.history.keys())


#Accuracy plot
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Cccuracy')
plt.xlabel('Epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

#Loss plot
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()